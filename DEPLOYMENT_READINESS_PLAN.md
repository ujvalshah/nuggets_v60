# ðŸš€ DEPLOYMENT READINESS EXECUTION PLAN

**Created:** 2025-12-28  
**Role:** Senior DevOps & Production Readiness Engineer  
**Consolidated From:** PRODUCTION_READINESS_ASSESSMENT.md, ChatGPT Audit, Gemini Audit  
**Target Timeline:** 2-3 weeks to production-ready

---

## ðŸ“Š EXECUTIVE SUMMARY

| Source | Overall Score | Primary Blockers |
|--------|---------------|------------------|
| Production Assessment | 6.5/10 | RegExp injection, No CI/CD, No tests, No Docker |
| ChatGPT Audit | 6/10 | Secrets in .env (ROTATE NOW), ReDoS, Missing Helmet verification |
| Gemini Audit | 6/10 | Demo login removal (verified clean), Rate limiting gaps |

### ðŸ”´ CRITICAL BLOCKERS (Must fix before ANY deployment)

1. **Security:** RegExp injection vulnerabilities (DoS risk) - 17 instances
2. **Security:** SSRF vulnerability in unfurl endpoint
3. **Security:** Rotate all secrets (if .env was ever committed)
4. **Infrastructure:** No Dockerfile (cannot deploy to modern platforms)
5. **CI/CD:** No GitHub Actions workflow (no quality gates)
6. **Quality:** Zero test coverage (high regression risk)

### âœ… VERIFIED SAFE

- Demo login backdoor: **REMOVED** (verified via codebase grep)
- `.env` in `.gitignore`: **CONFIRMED** (line 16)
- Helmet middleware: **ENABLED** (server/src/index.ts)
- CORS configuration: **PROPER** (strict in production)
- Rate limiting: **PRESENT** (login, signup, unfurl endpoints)
- Graceful shutdown: **IMPLEMENTED**
- Health check endpoint: **EXISTS** (`/api/health`)

---

## ðŸ“‹ PHASE 1: CRITICAL SECURITY FIXES (Days 1-2)

### 1.1 Create RegExp Escape Utility ðŸ”´ BLOCKER

**File to create:** `server/src/utils/escapeRegExp.ts`

```typescript
/**
 * Escapes special characters in a string for use in RegExp
 * Prevents ReDoS (Regular Expression Denial of Service) attacks
 * 
 * @example
 * const userInput = "user+search*query";
 * const safe = escapeRegExp(userInput);
 * const regex = new RegExp(safe, 'i'); // Safe to use
 */
export function escapeRegExp(s: string): string {
  return s.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
}
```

### 1.2 Fix All Unsafe RegExp Usages ðŸ”´ BLOCKER

**Files requiring fixes:**

| File | Line | Current (UNSAFE) | Fixed (SAFE) |
|------|------|------------------|--------------|
| `articlesController.ts` | 33 | `new RegExp(q.trim(), 'i')` | `new RegExp(escapeRegExp(q.trim()), 'i')` |
| `articlesController.ts` | 45 | `new RegExp(\`^${category.trim()}$\`, 'i')` | `new RegExp(\`^${escapeRegExp(category.trim())}$\`, 'i')` |
| `articlesController.ts` | 54 | Same pattern in map | Same fix |
| `collectionsController.ts` | 32 | `new RegExp(searchQuery, 'i')` | `new RegExp(escapeRegExp(searchQuery), 'i')` |
| `collectionsController.ts` | 161 | `new RegExp(\`^${name.trim()}$\`, 'i')` | `new RegExp(\`^${escapeRegExp(name.trim())}$\`, 'i')` |
| `usersController.ts` | 16 | `new RegExp(q.trim(), 'i')` | `new RegExp(escapeRegExp(q.trim()), 'i')` |
| `feedbackController.ts` | 48 | `new RegExp(q.trim(), 'i')` | `new RegExp(escapeRegExp(q.trim()), 'i')` |
| `moderationService.ts` | 32 | `new RegExp(filters.searchQuery.trim(), 'i')` | `new RegExp(escapeRegExp(filters.searchQuery.trim()), 'i')` |
| `collectionQueryHelpers.ts` | 53, 76 | `new RegExp(filters.searchQuery, 'i')` | `new RegExp(escapeRegExp(filters.searchQuery), 'i')` |
| `tagsController.ts` | 84 | `new RegExp(\`^${name.trim()}$\`, 'i')` | `new RegExp(\`^${escapeRegExp(name.trim())}$\`, 'i')` |

**Files already safe (no changes needed):**
- `checkUserByEmail.ts:31` - Already escapes input
- `bookmarkFoldersController.ts:154` - Already escapes input
- `aiController.ts:39-41` - Uses hardcoded video ID pattern, not user input

### 1.3 Add SSRF Protection to Unfurl ðŸ”´ BLOCKER

**File:** `server/src/utils/ssrfProtection.ts`

```typescript
import { URL } from 'url';

// Private IP ranges that should be blocked
const BLOCKED_IP_PATTERNS = [
  /^127\./,                    // Loopback
  /^10\./,                     // Private Class A
  /^172\.(1[6-9]|2\d|3[01])\./, // Private Class B
  /^192\.168\./,               // Private Class C
  /^169\.254\./,               // Link-local
  /^0\./,                      // Current network
  /^::1$/,                     // IPv6 loopback
  /^fc00:/i,                   // IPv6 private
  /^fe80:/i,                   // IPv6 link-local
];

// Blocked hostnames
const BLOCKED_HOSTNAMES = [
  'localhost',
  'localhost.localdomain',
  '0.0.0.0',
  'metadata.google.internal',  // GCP metadata
  'metadata',
];

// AWS metadata endpoints
const AWS_METADATA_IPS = ['169.254.169.254', '169.254.170.2'];

/**
 * Validates a URL is safe to fetch (prevents SSRF attacks)
 * @returns true if URL is safe, false if it should be blocked
 */
export function isUrlSafeForFetch(urlString: string): { safe: boolean; reason?: string } {
  try {
    const url = new URL(urlString);
    
    // Check protocol
    if (!['http:', 'https:'].includes(url.protocol)) {
      return { safe: false, reason: 'Invalid protocol' };
    }
    
    // Check blocked hostnames
    const hostname = url.hostname.toLowerCase();
    if (BLOCKED_HOSTNAMES.includes(hostname)) {
      return { safe: false, reason: 'Blocked hostname' };
    }
    
    // Check AWS metadata IPs
    if (AWS_METADATA_IPS.includes(hostname)) {
      return { safe: false, reason: 'Metadata endpoint blocked' };
    }
    
    // Check private IP patterns
    for (const pattern of BLOCKED_IP_PATTERNS) {
      if (pattern.test(hostname)) {
        return { safe: false, reason: 'Private IP range blocked' };
      }
    }
    
    // Check for IP-based hostnames that might bypass DNS
    const ipv4Pattern = /^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$/;
    if (ipv4Pattern.test(hostname)) {
      // Validate each octet
      const octets = hostname.split('.').map(Number);
      if (octets.some(o => o > 255)) {
        return { safe: false, reason: 'Invalid IP address' };
      }
    }
    
    return { safe: true };
  } catch {
    return { safe: false, reason: 'Invalid URL format' };
  }
}
```

**Update `unfurlController.ts`:**

```typescript
import { isUrlSafeForFetch } from '../utils/ssrfProtection.js';

// Add after protocol validation (line ~47):
const ssrfCheck = isUrlSafeForFetch(url);
if (!ssrfCheck.safe) {
  return res.status(400).json({
    error: 'URL not allowed',
    message: ssrfCheck.reason || 'URL validation failed',
  });
}
```

### 1.4 Rotate All Secrets (If .env Was Ever Committed)

**Action items:**
1. Check git history: `git log --all --full-history -- .env`
2. If found, immediately rotate:
   - MongoDB password (MongoDB Atlas â†’ Security â†’ Database Access)
   - JWT_SECRET (generate new): `node -e "console.log(require('crypto').randomBytes(32).toString('base64'))"`
   - Cloudinary credentials (if used)
   - GEMINI_API_KEYS (if used)
3. Clean git history (if needed): `git filter-repo --path .env --invert-paths`

---

## ðŸ“‹ PHASE 2: INFRASTRUCTURE SETUP (Days 3-4)

### 2.1 Create Multi-Stage Dockerfile ðŸ”´ BLOCKER

**File:** `Dockerfile`

```dockerfile
# ================================================
# STAGE 1: Build Frontend
# ================================================
FROM node:20-alpine AS frontend-build
WORKDIR /app

# Install dependencies first (better caching)
COPY package.json package-lock.json* ./
RUN npm ci --prefer-offline --no-audit --no-fund

# Copy source and build
COPY . .
RUN npm run build

# ================================================
# STAGE 2: Production Runtime
# ================================================
FROM node:20-alpine AS runtime
WORKDIR /app

# Security: Run as non-root user
RUN addgroup -S appgroup && adduser -S appuser -G appgroup

# Set production environment
ENV NODE_ENV=production
ENV PORT=5000

# Install only production dependencies
COPY package.json package-lock.json* ./
RUN npm ci --only=production --prefer-offline --no-audit --no-fund

# Copy built frontend from stage 1
COPY --from=frontend-build /app/dist ./dist

# Copy server source (tsx compiles at runtime)
COPY server ./server
COPY tsconfig.json ./

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:5000/api/health || exit 1

# Expose port
EXPOSE 5000

# Switch to non-root user
USER appuser

# Start server
CMD ["node", "--import", "tsx", "server/src/index.ts"]
```

### 2.2 Create Docker Compose for Local Development

**File:** `docker-compose.yml`

```yaml
version: '3.8'

services:
  # Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    env_file:
      - .env
    environment:
      - NODE_ENV=development
      - MONGO_URI=mongodb://mongo:27017/nuggets
    depends_on:
      mongo:
        condition: service_healthy
    volumes:
      # Mount source for hot reload in dev
      - ./src:/app/src:ro
      - ./server:/app/server:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MongoDB
  mongo:
    image: mongo:7.0
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis (for rate limiting in multi-instance deployments)
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  mongo_data:
  redis_data:
```

### 2.3 Create .dockerignore

**File:** `.dockerignore`

```
# Dependencies
node_modules
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Build outputs (we rebuild in Docker)
dist/

# Environment files
.env
.env.*
!env.example

# Git
.git
.gitignore

# IDE
.vscode
.idea
*.sw?

# Documentation (not needed in container)
*.md
!README.md

# Test files
**/*.test.ts
**/*.spec.ts
__tests__/
coverage/

# Development files
.eslintrc*
.prettierrc*
*.config.js
!vite.config.ts
!tailwind.config.js
!postcss.config.js

# Logs and temp files
logs/
tmp/
*.log
```

---

## ðŸ“‹ PHASE 3: CI/CD PIPELINE (Day 5)

### 3.1 Create GitHub Actions Workflow ðŸ”´ BLOCKER

**Directory:** `.github/workflows/`

**File:** `.github/workflows/ci.yml`

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, master, develop]
  pull_request:
    branches: [main, master]

env:
  NODE_VERSION: '20'

jobs:
  # ============================================
  # QUALITY CHECKS
  # ============================================
  quality:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run linter
        run: npm run lint

      - name: Type check
        run: npx tsc --noEmit

  # ============================================
  # SECURITY SCANNING
  # ============================================
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run npm audit
        run: npm audit --audit-level=high
        continue-on-error: true  # Don't fail build, but report

      - name: Run code audit
        run: npm run audit

  # ============================================
  # BUILD VERIFICATION
  # ============================================
  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [quality]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Verify build
        run: npm run build:verify

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 7

  # ============================================
  # TESTS (Enable when tests are added)
  # ============================================
  # test:
  #   name: Test
  #   runs-on: ubuntu-latest
  #   needs: [quality]
  #   steps:
  #     - uses: actions/checkout@v4
  #     - uses: actions/setup-node@v4
  #       with:
  #         node-version: ${{ env.NODE_VERSION }}
  #         cache: 'npm'
  #     - run: npm ci
  #     - run: npm test
  #     - name: Upload coverage
  #       uses: codecov/codecov-action@v4
  #       with:
  #         token: ${{ secrets.CODECOV_TOKEN }}

  # ============================================
  # DOCKER BUILD (Optional - for container deployments)
  # ============================================
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: nuggets:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

### 3.2 Add Dependabot Configuration

**File:** `.github/dependabot.yml`

```yaml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 10
    groups:
      development-dependencies:
        dependency-type: "development"
        update-types:
          - "minor"
          - "patch"
      production-dependencies:
        dependency-type: "production"
        update-types:
          - "patch"
```

---

## ðŸ“‹ PHASE 4: TESTING FRAMEWORK (Days 6-7)

### 4.1 Install Vitest and Testing Dependencies

```bash
npm install -D vitest @vitest/coverage-v8 supertest @types/supertest
```

### 4.2 Create Vitest Configuration

**File:** `vitest.config.ts`

```typescript
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    include: ['**/*.{test,spec}.{ts,tsx}'],
    exclude: ['node_modules', 'dist'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'dist/',
        '**/*.d.ts',
        '**/types/',
        'vitest.config.ts',
      ],
    },
    testTimeout: 10000,
  },
});
```

### 4.3 Add Test Scripts to package.json

```json
{
  "scripts": {
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage"
  }
}
```

### 4.4 Create Initial Test Files

**File:** `server/src/__tests__/escapeRegExp.test.ts`

```typescript
import { describe, it, expect } from 'vitest';
import { escapeRegExp } from '../utils/escapeRegExp';

describe('escapeRegExp', () => {
  it('should escape special regex characters', () => {
    const input = 'hello.*+?^${}()|[]\\world';
    const escaped = escapeRegExp(input);
    expect(escaped).toBe('hello\\.\\*\\+\\?\\^\\$\\{\\}\\(\\)\\|\\[\\]\\\\world');
  });

  it('should handle normal strings without changes', () => {
    const input = 'hello world';
    expect(escapeRegExp(input)).toBe('hello world');
  });

  it('should handle empty strings', () => {
    expect(escapeRegExp('')).toBe('');
  });

  it('should prevent ReDoS attack patterns', () => {
    // This pattern would cause catastrophic backtracking if not escaped
    const malicious = '(a+)+$';
    const escaped = escapeRegExp(malicious);
    const regex = new RegExp(escaped, 'i');
    
    // Should match literally, not as a pattern
    expect(regex.test('(a+)+$')).toBe(true);
    expect(regex.test('aaa')).toBe(false);
  });
});
```

**File:** `server/src/__tests__/ssrfProtection.test.ts`

```typescript
import { describe, it, expect } from 'vitest';
import { isUrlSafeForFetch } from '../utils/ssrfProtection';

describe('SSRF Protection', () => {
  describe('blocks internal addresses', () => {
    it('should block localhost', () => {
      expect(isUrlSafeForFetch('http://localhost/api').safe).toBe(false);
      expect(isUrlSafeForFetch('http://localhost:8080/api').safe).toBe(false);
    });

    it('should block 127.x.x.x addresses', () => {
      expect(isUrlSafeForFetch('http://127.0.0.1/').safe).toBe(false);
      expect(isUrlSafeForFetch('http://127.255.255.255/').safe).toBe(false);
    });

    it('should block AWS metadata endpoint', () => {
      expect(isUrlSafeForFetch('http://169.254.169.254/latest/meta-data/').safe).toBe(false);
    });

    it('should block private IP ranges', () => {
      expect(isUrlSafeForFetch('http://10.0.0.1/').safe).toBe(false);
      expect(isUrlSafeForFetch('http://192.168.1.1/').safe).toBe(false);
      expect(isUrlSafeForFetch('http://172.16.0.1/').safe).toBe(false);
    });
  });

  describe('allows public URLs', () => {
    it('should allow public domains', () => {
      expect(isUrlSafeForFetch('https://example.com/').safe).toBe(true);
      expect(isUrlSafeForFetch('https://github.com/user/repo').safe).toBe(true);
      expect(isUrlSafeForFetch('https://youtube.com/watch?v=123').safe).toBe(true);
    });
  });

  describe('validates protocol', () => {
    it('should block non-http protocols', () => {
      expect(isUrlSafeForFetch('file:///etc/passwd').safe).toBe(false);
      expect(isUrlSafeForFetch('ftp://server.com/file').safe).toBe(false);
      expect(isUrlSafeForFetch('javascript:alert(1)').safe).toBe(false);
    });
  });
});
```

---

## ðŸ“‹ PHASE 5: PRE-COMMIT HOOKS (Day 8)

### 5.1 Install Husky and lint-staged

```bash
npm install -D husky lint-staged
npx husky init
```

### 5.2 Configure lint-staged

**Add to `package.json`:**

```json
{
  "lint-staged": {
    "*.{ts,tsx}": [
      "eslint --fix",
      "prettier --write"
    ],
    "*.{json,md,yml,yaml}": [
      "prettier --write"
    ]
  }
}
```

### 5.3 Create Pre-commit Hook

**File:** `.husky/pre-commit`

```bash
#!/bin/sh
npx lint-staged
```

---

## ðŸ“‹ PHASE 6: PERFORMANCE OPTIMIZATION (Week 2)

### 6.1 Add Missing Database Indexes

**File:** `server/src/models/Article.ts` - Add indexes:

```typescript
// Add after schema definition
ArticleSchema.index({ authorId: 1 });
ArticleSchema.index({ publishedAt: -1 });
ArticleSchema.index({ categories: 1 });
ArticleSchema.index({ status: 1, publishedAt: -1 });

// Text index for search (replaces slow RegExp searches)
ArticleSchema.index(
  { title: 'text', excerpt: 'text', content: 'text' },
  { weights: { title: 10, excerpt: 5, content: 1 } }
);
```

### 6.2 Redis Store for Rate Limiting

**Install:** `npm install rate-limit-redis ioredis`

**Update:** `server/src/middleware/rateLimiter.ts`

```typescript
import { Redis } from 'ioredis';
import { RedisStore } from 'rate-limit-redis';

const redisClient = process.env.REDIS_URL 
  ? new Redis(process.env.REDIS_URL)
  : null;

const store = redisClient 
  ? new RedisStore({ sendCommand: (...args) => redisClient.call(...args) })
  : undefined;

// Use store in rate limiter config
export const loginLimiter = rateLimit({
  store, // Redis store for multi-instance
  windowMs: 15 * 60 * 1000,
  max: 5,
  // ...
});
```

---

## ðŸ“‹ DEPLOYMENT PLATFORM RECOMMENDATIONS

### Option A: Railway (Recommended for Quick Start)

**Pros:**
- Git-based deployments
- Auto-scaling
- Built-in Redis and MongoDB add-ons
- Free tier available

**Steps:**
1. Connect GitHub repository
2. Set environment variables
3. Add MongoDB and Redis add-ons
4. Deploy automatically on push

### Option B: Render

**Pros:**
- Similar to Railway
- Better free tier
- Native Docker support

### Option C: Vercel (Frontend) + Railway (Backend)

**Pros:**
- Best-in-class frontend performance
- Edge caching
- Split architecture for scaling

### Option D: AWS ECS/Fargate (Enterprise)

**Pros:**
- Full control
- Enterprise-grade reliability
- VPC security

---

## ðŸ“‹ CHECKLIST: MINIMUM VIABLE PRODUCTION

Before deploying, ensure ALL items are checked:

### Security âœ…
- [ ] All RegExp injection vulnerabilities fixed
- [ ] SSRF protection added to unfurl endpoint
- [ ] Secrets rotated (if ever committed)
- [ ] `.env` verified not in git history

### Infrastructure âœ…
- [ ] Dockerfile created and tested
- [ ] docker-compose.yml works locally
- [ ] Health check endpoint verified

### CI/CD âœ…
- [ ] GitHub Actions workflow created
- [ ] Lint and type-check passing
- [ ] Build verification working

### Testing âœ…
- [ ] Vitest configured
- [ ] At least security-critical tests written
- [ ] Tests passing in CI

### Documentation âœ…
- [ ] env.example up to date
- [ ] README includes deployment instructions
- [ ] All required environment variables documented

---

## ðŸ“… EXECUTION TIMELINE

| Day | Task | Priority | Effort |
|-----|------|----------|--------|
| 1 | Create escapeRegExp utility | ðŸ”´ Critical | 30 min |
| 1 | Fix all RegExp vulnerabilities | ðŸ”´ Critical | 2 hours |
| 1 | Add SSRF protection | ðŸ”´ Critical | 1 hour |
| 2 | Rotate secrets (if needed) | ðŸ”´ Critical | 1 hour |
| 3 | Create Dockerfile | ðŸ”´ Critical | 2 hours |
| 3 | Create docker-compose.yml | ðŸŸ¡ High | 1 hour |
| 4 | Create GitHub Actions workflow | ðŸ”´ Critical | 3 hours |
| 5 | Add Dependabot | ðŸŸ¡ High | 30 min |
| 6 | Setup Vitest | ðŸŸ¡ High | 2 hours |
| 6-7 | Write initial tests | ðŸŸ¡ High | 4 hours |
| 8 | Setup Husky + lint-staged | ðŸŸ¢ Medium | 1 hour |

**Total estimated effort:** 16-20 hours over 8 days

---

## ðŸŽ¯ POST-DEPLOYMENT MONITORING

After deployment, set up:

1. **Sentry Alerts:** Configure alert rules for error spikes
2. **Uptime Monitoring:** Use UptimeRobot or similar
3. **Log Aggregation:** Ship logs to Datadog/Papertrail
4. **Performance Monitoring:** Enable Sentry performance tracing

---

**Document Version:** 1.0  
**Last Updated:** 2025-12-28  
**Next Review:** After Phase 1 completion


